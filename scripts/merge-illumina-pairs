#!/bin/env python
# -*- coding: utf-8 -*-

import re
import os
import sys
import cPickle
import hashlib
import tempfile
import operator
import subprocess
import ConfigParser

sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)), '..'))

try:
    import Levenshtein as l
    LEVENSHTEIN_FOUND = True
except:
    print '''
    WARNING: --fast-merge parameter requires Levenshtein module, which seems to not installed on this machine. Here is a fast implementation of Levenshtein distance for Python:

        http://code.google.com/p/pylevenshtein/

'''
    LEVENSHTEIN_FOUND = False 


import fastqlib as u
import fastalib as f
from runconfiguration import RunConfiguration
from runconfiguration import ConfigError

def colorize(sequence):
    Green = lambda s: '\033[30m\033[42m' + s + '' + '\033[0m'
    return Green(sequence)

conv_dict = {'A': 'T',
             'T': 'A',
             'C': 'G',
             'G': 'C',
             'N': 'N'}

bases_upper_case = set(conv_dict.keys())

NumberOfConflicts = lambda s: sum([True for n in s if n in bases_upper_case])
ConflictPositions = lambda s: [i for i in range(0, len(s)) if s[i] in bases_upper_case]

def merge_two_sequences_fast(seq1, seq2, min_overlap_size = 10, debug = False):
    smallest, ind = sys.maxint, 0
    for i in range(min_overlap_size, len(seq1)):
        d = l.distance(seq1[-i:], seq2[:i])
        if d <= smallest:
            smallest = d
            ind = i

    beg = seq1[0:len(seq1) - ind].lower()
    overlap_1 = seq1[len(seq1) - ind:].lower()
    overlap_2 = seq2[:ind].lower()
    end = seq2[ind:].lower()
    overlap = ''
    
    mismatches = 0
    for i in range(0, len(overlap_1)):
        if overlap_1[i] != overlap_2[i]:
            mismatches += 1
            if reverse:
                overlap += overlap_2[i].upper()
            else:
                overlap += overlap_1[i].upper()
        else:
            overlap += overlap_1[i]

    if debug:
        print
        print beg + colorize(overlap) + end

    return beg + overlap + end


def merge_two_sequences(seq1, seq2, debug = False):
    temp_seq_1 = tempfile.NamedTemporaryFile(delete=False)
    temp_seq_1_path = temp_seq_1.name
    temp_seq_2 = tempfile.NamedTemporaryFile(delete=False)
    temp_seq_2_path = temp_seq_2.name
    temp_merge_path = tempfile.NamedTemporaryFile(delete=False).name
    
    temp_seq_1.write('>1\n' + seq1 + '\n')
    temp_seq_2.write('>2\n' + seq2 + '\n')
    
    temp_seq_1.close()
    temp_seq_2.close()

    merger_process = ['merger', temp_seq_1_path, temp_seq_2_path, '-outseq', temp_merge_path, '-gapopen', '25', '-outfile', '/dev/null']
    if subprocess.call(merger_process, stderr=open('/dev/null', 'w')) == 0:
        merged = f.SequenceSource(temp_merge_path)
        merged.next()
        merged.close()

        os.remove(temp_seq_1_path)
        os.remove(temp_seq_2_path)
        os.remove(temp_merge_path)

        if debug:
            overlap_beg = len(seq1) - (len(seq1) + len(seq2) - len(merged.seq))
            overlap_end = overlap_beg + (len(seq1) + len(seq2) - len(merged.seq))
            print
            print ''.join([merged.seq[:overlap_beg], colorize(merged.seq[overlap_beg:overlap_end]), merged.seq[overlap_end:]])

        return merged.seq
    else:
        print 'Something went wrong while merging these: \n\n%s\n--\n%s\n\n' % (seq1, seq2)
        sys.exit(-2)


def reverse_complement(seq):
    return ''.join(reversed([conv_dict[n] for n in seq]))


def reverse(seq):
    return ''.join(reversed(seq))


def complement(seq):
    return ''.join([conv_dict[n] for n in seq])


def main(config, output_file_prefix, compute_qual_dicts = False, min_overlap_size = 15, fast_merge = False, debug = False):

    actual_number_of_pairs = 0
    prefix_failed_in_pair_1_total = 0
    prefix_failed_in_pair_2_total = 0
    prefix_failed_in_both_pairs_total = 0
    passed_prefix_total = 0
    failed_prefix_total = 0
    merge_failed_total = 0
    merge_passed_total = 0
    num_mismatches_breakdown = {}
    num_mismatches_breakdown[0] = 0

    if config.pair_1_prefix:
        pair_1_prefix_compiled = re.compile(config.pair_1_prefix)
    else:
        pair_1_prefix_compiled = None
    
    if config.pair_2_prefix:
        pair_2_prefix_compiled = re.compile(config.pair_2_prefix)
    else:
        pair_2_prefix_compiled = None

    mean_quals_per_mismatch = {}

    output = f.FastaOutput(os.path.join(config.output_directory, output_file_prefix + '_MERGED' ))
    failed = f.FastaOutput(os.path.join(config.output_directory, output_file_prefix + '_FAILED' ))
    
    ########################################################################################################################
    # merging..
    ########################################################################################################################

    #sys.stderr.write('POK: "Percent of all pairs that did present the prefix defined by the user\n"')
    #sys.stderr.write('ZM : "Percent of all pairs that merged with 0 mismatch\n"')

    for index in range(0, len(config.pair_1)):
        try:
            F = lambda x: os.path.basename(x).split('.')[0]
            input_1 = u.FastQSource(config.pair_1[index], compressed = config.pair_1[index].endswith('.gz'))
            input_2 = u.FastQSource(config.pair_2[index], compressed = config.pair_2[index].endswith('.gz'))

        except u.FastQLibError, e:
            print "FastQLib is not happy.\n\n\t", e, "\n"
            sys.exit()

        while input_1.next() and input_2.next():
            actual_number_of_pairs += 1
            if input_1.p_available:
                if pair_1_prefix_compiled or pair_2_prefix_compiled:
                    input_1.print_percentage('[Merging %d of %d] POK: %.1f%% :: ZM: %.1f%%' \
                                % (index + 1,
                                   len(config.pair_1),
                                   passed_prefix_total * 100.0 / actual_number_of_pairs,
                                   num_mismatches_breakdown[0] * 100.0 / (passed_prefix_total or 1)
                                   ))
                else:
                    input_1.print_percentage('[Merging %d of %d]' % (index + 1, len(config.pair_1)))


            # taking care of prefixes if there are any..
            if pair_1_prefix_compiled:
                pattern_1 = pair_1_prefix_compiled.search(input_1.entry.sequence)
                if pattern_1:
                    input_1.entry.trim(trim_from = pattern_1.end())
                    
            if pair_2_prefix_compiled:
                pattern_2 = pair_2_prefix_compiled.search(input_2.entry.sequence)
                if pattern_2:
                    input_2.entry.trim(trim_from = pattern_2.end())

            failed_prefix = False
            
            if pair_1_prefix_compiled and (not pattern_1):
                failed_prefix = True
                prefix_failed_in_pair_1_total += 1
            if pair_2_prefix_compiled and (not pattern_2):
                failed_prefix = True
                prefix_failed_in_pair_2_total += 1
            if (pair_1_prefix_compiled and (not pattern_1)) and (pair_2_prefix_compiled and (not pattern_2)):
                prefix_failed_in_both_pairs_total += 1

            if failed_prefix:
                failed_prefix_total += 1
                continue
            if not failed_prefix:
                passed_prefix_total += 1

            # merging..
            if fast_merge:
                # uses Levenshtein distance.
                merged_sequence = merge_two_sequences_fast(input_1.entry.sequence, reverse_complement(input_2.entry.sequence), min_overlap_size, debug)
            else:
                # uses EMBOSS 'merger'
                merged_sequence = merge_two_sequences(input_1.entry.sequence, reverse_complement(input_2.entry.sequence), debug)
            
            number_of_mismatches = NumberOfConflicts(merged_sequence)
            len_overlap = (len(input_1.entry.sequence) + len(input_2.entry.sequence)) - len(merged_sequence)
           
            
            if not num_mismatches_breakdown.has_key(number_of_mismatches):
                num_mismatches_breakdown[number_of_mismatches] = 1
            else:
                num_mismatches_breakdown[number_of_mismatches] += 1

            p = 1.0 * number_of_mismatches / len_overlap

            if p > 0.3 or len_overlap < min_overlap_size:
                failed.write_id('%s|o:%d|o/m:%f|mismatches:%d' % (input_1.entry.header_line, len_overlap, p, number_of_mismatches))
                failed.write_seq(merged_sequence, split = False)
                merge_failed_total += 1
            else:
                output.write_id('%s|o:%d|o/m:%f|mismatches:%d' % (input_1.entry.header_line, len_overlap, p, number_of_mismatches))
                output.write_seq(merged_sequence, split = False)
                merge_passed_total += 1

            if compute_qual_dicts:
                ################ quality dicts associated stuff ####################
                q1 = input_1.entry.process_Q_list()
                q2 = input_2.entry.process_Q_list()
                tile_number = input_1.entry.tile_number
              
                if number_of_mismatches >= 10:
                    ind = 10
                else:
                    ind = number_of_mismatches

                if not mean_quals_per_mismatch.has_key(ind):
                    mean_quals_per_mismatch[ind] = {}

                tiles_dict = mean_quals_per_mismatch[ind]

                if not tiles_dict.has_key('1'):
                    tiles_dict['1'] = {}
                if not tiles_dict.has_key('2'):
                    tiles_dict['2'] = {}

                if not tiles_dict['1'].has_key(tile_number):
                    tiles_dict['1'][tile_number] = {'mean': [0] * len(q1), 'std': [0] * len(q1), 'count': [0] * len(q1)}
                if not tiles_dict['2'].has_key(tile_number):
                    tiles_dict['2'][tile_number] = {'mean': [0] * len(q2), 'std': [0] * len(q2), 'count': [0] * len(q2)}

                for i in range(0, len(q1)):
                    tiles_dict['1'][tile_number]['mean'][i] += q1[i]
                    tiles_dict['1'][tile_number]['count'][i] += 1
                for i in range(0, len(q2)):
                    tiles_dict['2'][tile_number]['mean'][i] += q2[i]
                    tiles_dict['2'][tile_number]['count'][i] += 1
                    
                ################ / quality dicts associated stuff ####################
 
        print
        input_1.close()
        input_2.close()

    output.close()
    failed.close()

    stats = open(os.path.join(config.output_directory, output_file_prefix + '_STATS'), 'w')
    stats.write('Number of pairs analyzed\t%d\n' % actual_number_of_pairs)
    stats.write('Prefix failed in Pair 1 \t%d\n' % prefix_failed_in_pair_1_total)
    stats.write('Prefix failed in Pair 2 \t%d\n' % prefix_failed_in_pair_2_total)
    stats.write('Prefix failed in both   \t%d\n' % prefix_failed_in_both_pairs_total)
    stats.write('Passed prefix total     \t%d\n' % passed_prefix_total)
    stats.write('Failed prefix total     \t%d\n' % failed_prefix_total)
    stats.write('Merged total            \t%d\n' % merge_passed_total)
    stats.write('Merge failed total      \t%d\n' % merge_failed_total)
    stats.write('\nMismatches breakdown:\n\n')

    for i in sorted(num_mismatches_breakdown.keys()):
        stats.write('%d\t%d\n' % (i, num_mismatches_breakdown[i]))
    
    stats.write('\n\nCommand line            \t%s\n' % ' '.join(sys.argv))
    stats.write('Work directory              \t%s\n' % os.getcwd())

    stats.close()

    if compute_qual_dicts:
        ################ quality dicts associated stuff ####################
        #finalizing mean_quals_per_mismatch dict:
        for ind in mean_quals_per_mismatch.keys():
            for pair in ['1', '2']:
                for tile in mean_quals_per_mismatch[ind][pair]:
                    for i in range(0, len(mean_quals_per_mismatch[ind][pair][tile]['mean'])):
                        mean_quals_per_mismatch[ind][pair][tile]['mean'][i] = mean_quals_per_mismatch[ind][pair][tile]['mean'][i] * 1.0 \
                                                                              / mean_quals_per_mismatch[ind][pair][tile]['count'][i]

        # visualizing quals
        for ind in mean_quals_per_mismatch.keys():
            sys.stderr.write('\rVisualizing Qual Scores: %d of %d' % (mean_quals_per_mismatch.keys().index(ind) + 1, len(mean_quals_per_mismatch.keys())))
            sys.stderr.flush()
            u.visualize_qual_stats_dict(mean_quals_per_mismatch[ind], os.path.join(config.output_directory, output_file_prefix + '_QUALS_%d_MISMATCH' % ind),\
                                        title = 'Machine Reported Mean PHRED Scores for Pairs Merged with %d Mismatches' % ind if ind != 1 else \
                                                'Machine Reported Mean PHRED Scores for Pairs Merged with 1 Mismatch')
        print
        ################ / quality dicts associated stuff ####################


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Merge Overlapping Paired-End Illumina Reads')
    parser.add_argument('user_config', metavar = 'CONFIG_FILE',
                                        help = 'User configuration to run')
    parser.add_argument('output_file_prefix', metavar = 'OUTPUT_FILE_PREFIX',
                                        help = 'Output file prefix (which will be used as a prefix\
                                                for files that appear in output directory)')
    parser.add_argument('--min-overlap-size', type = int, default = 15,
                                        help = 'Minimum expected overlap. Default is %(default)d.')
    parser.add_argument('--compute-qual-dicts', action = 'store_true', default = False,
                                        help = 'When set, qual ditcs will be computed. May take a\
                                                very long time for datasets with more than a\
                                                million pairs.')
    parser.add_argument('--fast-merge', action = 'store_true', default = False,
                                        help = 'When set, merging operation is performed using\
                                                Levenshtein distance. Otherwise "merger" tool\
                                                in EMBOSS package is being used. Levenshtein is\
                                                fast, but merger will give you more accurate\
                                                results, since Levenshtein method cannot handle\
                                                insertion or deletion errors well.')
    parser.add_argument('--debug', action = 'store_true', default = False,
                                        help = 'When set, debug messages will be printed')

    args = parser.parse_args()
    user_config = ConfigParser.ConfigParser()
    user_config.read(args.user_config)

    try: 
        config = RunConfiguration(user_config)
    except ConfigError, e:
        print "There is something wrong with the config file. This is what we know: \n\n", e
        print
        sys.exit()

    if args.fast_merge and not LEVENSHTEIN_FOUND:
        print "\n    WARNING: You declared --fast-merge, but there is no module for Levenshtein distance computation. Falling back to default.\n\n"
        args.fast_merge = False

    sys.exit(main(config,
                  args.output_file_prefix,
                  args.compute_qual_dicts,
                  args.min_overlap_size,
                  args.fast_merge,
                  args.debug))
